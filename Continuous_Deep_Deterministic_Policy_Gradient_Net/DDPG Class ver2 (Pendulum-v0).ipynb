{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Deterministic Policy Gradient\n",
    "Implementation followed: Continuous control with deep reinforcement learning (arXiv:1509.02971v5)\n",
    "- Memory Relay\n",
    "- A3C\n",
    "- Trained with a target net\n",
    "- Initial exploration policy is quite important to warm up the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-26T21:22:27.814572\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now().isoformat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Actor(object):\n",
    "    def __init__(self, n_observation, n_action, name='actor_net'):\n",
    "        self.n_observation = n_observation\n",
    "        self.n_action = n_action\n",
    "        self.name = name\n",
    "        self.sess = None\n",
    "        self.build_model()\n",
    "        self.build_train()\n",
    "        \n",
    "    def build_model(self):\n",
    "        activation = tf.nn.elu\n",
    "        kernel_initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "        kernel_regularizer = tf.contrib.layers.l2_regularizer(0.01)\n",
    "        default_dense = partial(tf.layers.dense,\\\n",
    "                                activation=activation,\\\n",
    "                                kernel_initializer=kernel_initializer,\\\n",
    "                                kernel_regularizer=kernel_regularizer)\n",
    "        with tf.variable_scope(self.name) as scope:\n",
    "            observation = tf.placeholder(tf.float32,shape=[None,self.n_observation])\n",
    "            hid1 = default_dense(observation,32)\n",
    "            hid2 = default_dense(hid1,64)\n",
    "            action = default_dense(hid2,self.n_action,activation=tf.nn.tanh,use_bias=False)\n",
    "            trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=self.name)\n",
    "        self.observation,self.action,self.trainable_vars = observation,action,trainable_vars\n",
    "        \n",
    "    def build_train(self,learning_rate = 0.0001):\n",
    "        with tf.variable_scope(self.name) as scope:\n",
    "            action_grads = tf.placeholder(tf.float32,[None,self.n_action])\n",
    "            var_grads = tf.gradients(self.action,self.trainable_vars,-action_grads)\n",
    "            train_op = tf.train.AdamOptimizer(learning_rate).apply_gradients(zip(var_grads,self.trainable_vars))\n",
    "        self.action_grads,self.train_op = action_grads,train_op\n",
    "        \n",
    "    def predict_action(self,obs_batch):\n",
    "        return self.action.eval(session=self.sess,feed_dict={self.observation:obs_batch})\n",
    "\n",
    "    def train(self,obs_batch,action_grads):\n",
    "        batch_size = len(action_grads)\n",
    "        self.train_op.run(session=self.sess,feed_dict={self.observation:obs_batch,self.action_grads:action_grads/batch_size})\n",
    "        \n",
    "    def set_session(self,sess):\n",
    "        self.sess = sess\n",
    "        \n",
    "    def get_trainable_dict(self):\n",
    "        return {var.name[len(self.name):]: var for var in self.trainable_vars}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Critic(object):\n",
    "    def __init__(self, n_observation, n_action, name='critic_net'):\n",
    "        self.n_observation = n_observation\n",
    "        self.n_action = n_action\n",
    "        self.name = name\n",
    "        self.sess = None\n",
    "        self.build_model()\n",
    "        self.build_train()\n",
    "        \n",
    "    def build_model(self):\n",
    "        activation = tf.nn.elu\n",
    "        kernel_initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "        kernel_regularizer = tf.contrib.layers.l2_regularizer(0.01)\n",
    "        default_dense = partial(tf.layers.dense,\\\n",
    "                                activation=activation,\\\n",
    "                                kernel_initializer=kernel_initializer,\\\n",
    "                                kernel_regularizer=kernel_regularizer)\n",
    "        with tf.variable_scope(self.name) as scope:\n",
    "            observation = tf.placeholder(tf.float32,shape=[None,self.n_observation])\n",
    "            action = tf.placeholder(tf.float32,shape=[None,self.n_action])\n",
    "            hid1 = default_dense(observation,32)\n",
    "            hid2 = default_dense(action,32)\n",
    "            hid3 = tf.concat([hid1,hid2],axis=1)\n",
    "            hid4 = default_dense(hid3,128)\n",
    "            Q = default_dense(hid4,1, activation=None)\n",
    "            trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=self.name)\n",
    "        self.observation,self.action,self.Q,self.trainable_vars= observation,action,Q,trainable_vars\n",
    "    \n",
    "    def build_train(self,learning_rate=0.001):\n",
    "        with tf.variable_scope(self.name) as scope:\n",
    "            Qexpected = tf.placeholder(tf.float32,shape=[None,1])\n",
    "            loss = tf.losses.mean_squared_error(Qexpected,self.Q)\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            train_op = optimizer.minimize(loss)\n",
    "        self.Qexpected,self.train_op = Qexpected,train_op\n",
    "        self.action_grads = tf.gradients(self.Q,self.action)[0]\n",
    "    \n",
    "    def predict_Q(self,obs_batch,action_batch):\n",
    "        return self.Q.eval(session=self.sess,\\\n",
    "                           feed_dict={self.observation:obs_batch,self.action:action_batch})\n",
    "    \n",
    "    def compute_action_grads(self,obs_batch,action_batch):\n",
    "        return self.action_grads.eval(session=self.sess,\\\n",
    "                               feed_dict={self.observation:obs_batch,self.action:action_batch})\n",
    "    def train(self,obs_batch,action_batch,Qexpected_batch):\n",
    "        self.train_op.run(session=self.sess,\\\n",
    "                          feed_dict={self.observation:obs_batch,self.action:action_batch,self.Qexpected:Qexpected_batch})\n",
    "    \n",
    "    def set_session(self,sess):\n",
    "        self.sess = sess\n",
    "        \n",
    "    def get_trainable_dict(self):\n",
    "        return {var.name[len(self.name):]: var for var in self.trainable_vars}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AsyncNets(object):\n",
    "    def __init__(self,class_name):\n",
    "        class_ = eval(class_name)\n",
    "        self.net = class_(3,1,name=class_name)\n",
    "        self.target_net = class_(3,1,name='{}_target'.format(class_name))\n",
    "        self.TAU = tf.placeholder(tf.float32,shape=None)\n",
    "        self.sess = None\n",
    "        self.__build_async_assign()\n",
    "    \n",
    "    def __build_async_assign(self):\n",
    "        net_dict = self.net.get_trainable_dict()\n",
    "        target_net_dict = self.target_net.get_trainable_dict()\n",
    "        keys = net_dict.keys()\n",
    "        async_update_op = [target_net_dict[key].assign((1-self.TAU)*target_net_dict[key]+self.TAU*net_dict[key]) \\\n",
    "                           for key in keys]\n",
    "        self.async_update_op = async_update_op\n",
    "    \n",
    "    def async_update(self,tau=0.01):\n",
    "        self.sess.run(self.async_update_op,feed_dict={self.TAU:tau})\n",
    "    \n",
    "    def set_session(self,sess):\n",
    "        self.sess = sess\n",
    "        self.net.set_session(sess)\n",
    "        self.target_net.set_session(sess)\n",
    "    \n",
    "    def get_subnets(self):\n",
    "        return self.net, self.target_net\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Memory(object):\n",
    "    def __init__(self,memory_size=10000):\n",
    "        self.memory = deque(maxlen=memory_size)\n",
    "        self.memory_size = memory_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "    def append(self,item):\n",
    "        self.memory.append(item)\n",
    "        \n",
    "    def sample_batch(self,batch_size=256):\n",
    "        idx = np.random.permutation(len(self.memory))[:batch_size]\n",
    "        return [self.memory[i] for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def UONoise():\n",
    "    theta = 0.15\n",
    "    sigma = 0.2\n",
    "    state = 0\n",
    "    while True:\n",
    "        yield state\n",
    "        state += -theta*state+sigma*np.random.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-26 21:22:36,925] Making new env: Pendulum-v0\n",
      "[2017-08-26 21:22:36,973] Clearing 18 monitor files from previous run (because force=True was provided)\n",
      "[2017-08-26 21:22:36,975] Starting new video recorder writing to /Users/winter/Google Drive/handson-ml/tmp/openaigym.video.0.1408.video000000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 193, ep 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-26 21:22:41,880] Starting new video recorder writing to /Users/winter/Google Drive/handson-ml/tmp/openaigym.video.0.1408.video000001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 199, ep 0, score -1064.337803, steps 200\n",
      "iter 399, ep 1, score -1452.929239, steps 200\n",
      "iter 599, ep 2, score -900.730704, steps 200\n",
      "iter 799, ep 3, score -979.678247, steps 200\n",
      "iter 999, ep 4, score -1464.379648, steps 200\n",
      "iter 1199, ep 5, score -964.648093, steps 200\n",
      "iter 1399, ep 6, score -1625.818235, steps 200\n",
      "iter 1591, ep 7"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-26 21:22:51,209] Starting new video recorder writing to /Users/winter/Google Drive/handson-ml/tmp/openaigym.video.0.1408.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1599, ep 7, score -1263.597151, steps 200\n",
      "iter 1799, ep 8, score -1451.116410, steps 200\n",
      "iter 1999, ep 9, score -992.277210, steps 200\n",
      "iter 2199, ep 10, score -1620.274533, steps 200\n",
      "iter 2399, ep 11, score -1731.880773, steps 200\n",
      "iter 2599, ep 12, score -1094.504865, steps 200\n",
      "iter 2799, ep 13, score -1741.083284, steps 200\n",
      "iter 2999, ep 14, score -1442.242095, steps 200\n",
      "iter 3199, ep 15, score -1098.027994, steps 200\n",
      "iter 3399, ep 16, score -1098.776404, steps 200\n",
      "iter 3599, ep 17, score -1798.072430, steps 200\n",
      "iter 3799, ep 18, score -1092.271777, steps 200\n",
      "iter 3999, ep 19, score -1021.271582, steps 200\n",
      "iter 4199, ep 20, score -1223.411688, steps 200\n",
      "iter 4399, ep 21, score -1309.548927, steps 200\n",
      "iter 4599, ep 22, score -1027.574288, steps 200\n",
      "iter 4799, ep 23, score -1188.868957, steps 200\n",
      "iter 4999, ep 24, score -1140.436419, steps 200\n",
      "iter 5199, ep 25, score -1235.387716, steps 200\n",
      "iter 5391, ep 26"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-26 21:23:18,553] Starting new video recorder writing to /Users/winter/Google Drive/handson-ml/tmp/openaigym.video.0.1408.video000027.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5399, ep 26, score -987.548204, steps 200\n",
      "iter 5599, ep 27, score -1619.530272, steps 200\n",
      "iter 5799, ep 28, score -968.738765, steps 200\n",
      "iter 5999, ep 29, score -988.404297, steps 200\n",
      "iter 6199, ep 30, score -858.700286, steps 200\n",
      "iter 6399, ep 31, score -1725.719085, steps 200\n",
      "iter 6599, ep 32, score -1411.769340, steps 200\n",
      "iter 6799, ep 33, score -1499.526679, steps 200\n",
      "iter 6999, ep 34, score -1111.330258, steps 200\n",
      "iter 7199, ep 35, score -1268.784305, steps 200\n",
      "iter 7399, ep 36, score -1227.741326, steps 200\n",
      "iter 7599, ep 37, score -1479.133063, steps 200\n",
      "iter 7799, ep 38, score -1403.646349, steps 200\n",
      "iter 7999, ep 39, score -1484.729898, steps 200\n",
      "iter 8199, ep 40, score -1298.216238, steps 200\n",
      "iter 8399, ep 41, score -1098.002777, steps 200\n",
      "iter 8599, ep 42, score -1182.987359, steps 200\n",
      "iter 8799, ep 43, score -1471.492544, steps 200\n",
      "iter 8999, ep 44, score -1211.134201, steps 200\n",
      "iter 9199, ep 45, score -1132.366484, steps 200\n",
      "iter 9399, ep 46, score -1160.883524, steps 200\n",
      "iter 9599, ep 47, score -992.302824, steps 200\n",
      "iter 9799, ep 48, score -980.710118, steps 200\n",
      "iter 9999, ep 49, score -1008.958237, steps 200\n",
      "iter 10199, ep 50, score -807.954371, steps 200\n",
      "iter 10399, ep 51, score -1101.055201, steps 200\n",
      "iter 10599, ep 52, score -1165.670182, steps 200\n",
      "iter 10799, ep 53, score -1144.186126, steps 200\n",
      "iter 10999, ep 54, score -977.523134, steps 200\n",
      "iter 11199, ep 55, score -753.598748, steps 200\n",
      "iter 11399, ep 56, score -1039.993851, steps 200\n",
      "iter 11599, ep 57, score -638.446753, steps 200\n",
      "iter 11799, ep 58, score -753.432776, steps 200\n",
      "iter 11999, ep 59, score -377.969747, steps 200\n",
      "iter 12199, ep 60, score -255.884073, steps 200\n",
      "iter 12399, ep 61, score -251.304605, steps 200\n",
      "iter 12599, ep 62, score -480.490893, steps 200\n",
      "iter 12788, ep 63"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-26 21:24:08,642] Starting new video recorder writing to /Users/winter/Google Drive/handson-ml/tmp/openaigym.video.0.1408.video000064.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 12799, ep 63, score -514.583627, steps 200\n",
      "iter 12999, ep 64, score -492.792294, steps 200\n",
      "iter 13199, ep 65, score -0.809584, steps 200\n",
      "iter 13399, ep 66, score -128.301171, steps 200\n",
      "iter 13599, ep 67, score -129.260956, steps 200\n",
      "iter 13799, ep 68, score -377.287180, steps 200\n",
      "iter 13999, ep 69, score -368.860775, steps 200\n",
      "iter 14199, ep 70, score -123.629120, steps 200\n",
      "iter 14399, ep 71, score -384.817258, steps 200\n",
      "iter 14599, ep 72, score -0.677299, steps 200\n",
      "iter 14799, ep 73, score -370.016429, steps 200\n",
      "iter 14999, ep 74, score -259.441145, steps 200\n",
      "iter 15199, ep 75, score -237.910846, steps 200\n",
      "iter 15399, ep 76, score -119.175965, steps 200\n",
      "iter 15599, ep 77, score -516.978731, steps 200\n",
      "iter 15799, ep 78, score -1344.161227, steps 200\n",
      "iter 15999, ep 79, score -0.807787, steps 200\n",
      "iter 16199, ep 80, score -114.978708, steps 200\n",
      "iter 16399, ep 81, score -768.592530, steps 200\n",
      "iter 16599, ep 82, score -128.405298, steps 200\n",
      "iter 16799, ep 83, score -0.127020, steps 200\n",
      "iter 16999, ep 84, score -349.809474, steps 200\n",
      "iter 17199, ep 85, score -964.106506, steps 200\n",
      "iter 17399, ep 86, score -0.359138, steps 200\n",
      "iter 17599, ep 87, score -1188.854105, steps 200\n",
      "iter 17799, ep 88, score -1182.499609, steps 200\n",
      "iter 17999, ep 89, score -119.868426, steps 200\n",
      "iter 18199, ep 90, score -374.429581, steps 200\n",
      "iter 18399, ep 91, score -243.802135, steps 200\n",
      "iter 18599, ep 92, score -240.095410, steps 200\n",
      "iter 18799, ep 93, score -118.592989, steps 200\n",
      "iter 18999, ep 94, score -122.878965, steps 200\n",
      "iter 19199, ep 95, score -123.732260, steps 200\n",
      "iter 19399, ep 96, score -122.181211, steps 200\n",
      "iter 19599, ep 97, score -252.719152, steps 200\n",
      "iter 19799, ep 98, score -128.893474, steps 200\n",
      "iter 19999, ep 99, score -255.153885, steps 200\n",
      "iter 20199, ep 100, score -244.093991, steps 200\n",
      "iter 20399, ep 101, score -245.012112, steps 200\n",
      "iter 20599, ep 102, score -125.532636, steps 200\n",
      "iter 20799, ep 103, score -281.169863, steps 200\n",
      "iter 20999, ep 104, score -358.179986, steps 200\n",
      "iter 21199, ep 105, score -124.554989, steps 200\n",
      "iter 21399, ep 106, score -263.171641, steps 200\n",
      "iter 21599, ep 107, score -243.242076, steps 200\n",
      "iter 21799, ep 108, score -1.345710, steps 200\n",
      "iter 21999, ep 109, score -132.690177, steps 200\n",
      "iter 22199, ep 110, score -124.921505, steps 200\n",
      "iter 22399, ep 111, score -126.223287, steps 200\n",
      "iter 22599, ep 112, score -123.857903, steps 200\n",
      "iter 22799, ep 113, score -129.218141, steps 200\n",
      "iter 22999, ep 114, score -126.714810, steps 200\n",
      "iter 23199, ep 115, score -3.717351, steps 200\n",
      "iter 23399, ep 116, score -242.727221, steps 200\n",
      "iter 23599, ep 117, score -252.102512, steps 200\n",
      "iter 23799, ep 118, score -131.549840, steps 200\n",
      "iter 23999, ep 119, score -131.233809, steps 200\n",
      "iter 24199, ep 120, score -131.400693, steps 200\n",
      "iter 24399, ep 121, score -261.426106, steps 200\n",
      "iter 24599, ep 122, score -253.119367, steps 200\n",
      "iter 24799, ep 123, score -259.357212, steps 200\n",
      "iter 24984, ep 124"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-26 21:25:33,603] Starting new video recorder writing to /Users/winter/Google Drive/handson-ml/tmp/openaigym.video.0.1408.video000125.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 24999, ep 124, score -260.784997, steps 200\n",
      "iter 25199, ep 125, score -125.729126, steps 200\n",
      "iter 25399, ep 126, score -260.855328, steps 200\n",
      "iter 25599, ep 127, score -385.974153, steps 200\n",
      "iter 25799, ep 128, score -127.646294, steps 200\n",
      "iter 25999, ep 129, score -250.428526, steps 200\n",
      "iter 26199, ep 130, score -270.953140, steps 200\n",
      "iter 26399, ep 131, score -389.787544, steps 200\n",
      "iter 26599, ep 132, score -250.267412, steps 200\n",
      "iter 26799, ep 133, score -257.369616, steps 200\n",
      "iter 26999, ep 134, score -375.464715, steps 200\n",
      "iter 27199, ep 135, score -335.487404, steps 200\n",
      "iter 27399, ep 136, score -262.835743, steps 200\n",
      "iter 27599, ep 137, score -492.912502, steps 200\n",
      "iter 27799, ep 138, score -259.321548, steps 200\n",
      "iter 27999, ep 139, score -364.541715, steps 200\n",
      "iter 28199, ep 140, score -129.515003, steps 200\n",
      "iter 28399, ep 141, score -240.775872, steps 200\n",
      "iter 28599, ep 142, score -243.228757, steps 200\n",
      "iter 28799, ep 143, score -245.208978, steps 200\n",
      "iter 28999, ep 144, score -355.964859, steps 200\n",
      "iter 29199, ep 145, score -129.415597, steps 200\n",
      "iter 29399, ep 146, score -250.975489, steps 200\n",
      "iter 29599, ep 147, score -252.039610, steps 200\n",
      "iter 29799, ep 148, score -244.715129, steps 200\n",
      "iter 29999, ep 149, score -130.504347, steps 200\n",
      "iter 30199, ep 150, score -354.974179, steps 200\n",
      "iter 30399, ep 151, score -117.845393, steps 200\n",
      "iter 30599, ep 152, score -260.611639, steps 200\n",
      "iter 30799, ep 153, score -4.214091, steps 200\n",
      "iter 30999, ep 154, score -4.594981, steps 200\n",
      "iter 31199, ep 155, score -239.442948, steps 200\n",
      "iter 31399, ep 156, score -238.317667, steps 200\n",
      "iter 31599, ep 157, score -1059.610431, steps 200\n",
      "iter 31799, ep 158, score -242.727606, steps 200\n",
      "iter 31999, ep 159, score -259.869131, steps 200\n",
      "iter 32199, ep 160, score -128.741351, steps 200\n",
      "iter 32399, ep 161, score -3.639193, steps 200\n",
      "iter 32599, ep 162, score -236.103353, steps 200\n",
      "iter 32799, ep 163, score -130.198551, steps 200\n",
      "iter 32999, ep 164, score -238.857995, steps 200\n",
      "iter 33199, ep 165, score -117.932390, steps 200\n",
      "iter 33399, ep 166, score -377.000371, steps 200\n",
      "iter 33599, ep 167, score -124.129138, steps 200\n",
      "iter 33799, ep 168, score -121.294558, steps 200\n",
      "iter 33999, ep 169, score -1186.945392, steps 200\n",
      "iter 34199, ep 170, score -1233.404024, steps 200\n",
      "iter 34399, ep 171, score -130.510697, steps 200\n",
      "iter 34599, ep 172, score -4.982641, steps 200\n",
      "iter 34799, ep 173, score -131.216311, steps 200\n",
      "iter 34999, ep 174, score -378.319176, steps 200\n",
      "iter 35199, ep 175, score -298.653596, steps 200\n",
      "iter 35399, ep 176, score -251.740129, steps 200\n",
      "iter 35599, ep 177, score -277.894682, steps 200\n",
      "iter 35799, ep 178, score -135.317220, steps 200\n",
      "iter 35999, ep 179, score -127.316735, steps 200\n",
      "iter 36199, ep 180, score -132.822921, steps 200\n",
      "iter 36399, ep 181, score -130.992163, steps 200\n",
      "iter 36599, ep 182, score -266.365690, steps 200\n",
      "iter 36799, ep 183, score -7.579537, steps 200\n",
      "iter 36999, ep 184, score -239.702124, steps 200\n",
      "iter 37199, ep 185, score -119.325143, steps 200\n",
      "iter 37399, ep 186, score -120.196804, steps 200\n",
      "iter 37599, ep 187, score -125.847208, steps 200\n",
      "iter 37799, ep 188, score -131.916780, steps 200\n",
      "iter 37999, ep 189, score -239.109891, steps 200\n",
      "iter 38199, ep 190, score -5.310116, steps 200\n",
      "iter 38399, ep 191, score -350.563647, steps 200\n",
      "iter 38599, ep 192, score -352.134777, steps 200\n",
      "iter 38799, ep 193, score -126.908148, steps 200\n",
      "iter 38999, ep 194, score -129.344405, steps 200\n",
      "iter 39199, ep 195, score -129.438627, steps 200\n",
      "iter 39399, ep 196, score -127.880176, steps 200\n",
      "iter 39599, ep 197, score -246.035287, steps 200\n",
      "iter 39799, ep 198, score -234.146873, steps 200\n",
      "iter 39999, ep 199, score -122.887167, steps 200\n",
      "iter 40199, ep 200, score -4.577153, steps 200\n",
      "iter 40399, ep 201, score -131.089583, steps 200\n",
      "iter 40599, ep 202, score -344.935548, steps 200\n",
      "iter 40799, ep 203, score -117.195885, steps 200\n",
      "iter 40999, ep 204, score -303.608026, steps 200\n",
      "iter 41199, ep 205, score -124.968612, steps 200\n",
      "iter 41399, ep 206, score -126.725937, steps 200\n",
      "iter 41599, ep 207, score -114.673181, steps 200\n",
      "iter 41799, ep 208, score -249.000591, steps 200\n",
      "iter 41999, ep 209, score -1.623344, steps 200\n",
      "iter 42199, ep 210, score -1.010534, steps 200\n",
      "iter 42399, ep 211, score -123.786262, steps 200\n",
      "iter 42599, ep 212, score -125.591439, steps 200\n",
      "iter 42799, ep 213, score -2.525032, steps 200\n",
      "iter 42999, ep 214, score -265.754485, steps 200\n",
      "iter 43172, ep 215"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-26 21:27:37,112] Starting new video recorder writing to /Users/winter/Google Drive/handson-ml/tmp/openaigym.video.0.1408.video000216.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 43199, ep 215, score -125.225655, steps 200\n",
      "iter 43399, ep 216, score -3.873638, steps 200\n",
      "iter 43599, ep 217, score -122.130962, steps 200\n",
      "iter 43799, ep 218, score -124.214464, steps 200\n",
      "iter 43999, ep 219, score -127.464848, steps 200\n",
      "iter 44199, ep 220, score -360.385836, steps 200\n",
      "iter 44399, ep 221, score -240.291437, steps 200\n",
      "iter 44599, ep 222, score -240.390900, steps 200\n",
      "iter 44799, ep 223, score -124.180430, steps 200\n",
      "iter 44999, ep 224, score -116.245345, steps 200\n",
      "iter 45199, ep 225, score -117.838239, steps 200\n",
      "iter 45399, ep 226, score -124.368810, steps 200\n",
      "iter 45599, ep 227, score -125.467418, steps 200\n",
      "iter 45799, ep 228, score -120.172418, steps 200\n",
      "iter 45999, ep 229, score -118.514655, steps 200\n",
      "iter 46199, ep 230, score -5.093049, steps 200\n",
      "iter 46399, ep 231, score -135.675310, steps 200\n",
      "iter 46599, ep 232, score -258.219327, steps 200\n",
      "iter 46799, ep 233, score -233.724384, steps 200\n",
      "iter 46999, ep 234, score -5.685182, steps 200\n",
      "iter 47199, ep 235, score -4.681136, steps 200\n",
      "iter 47399, ep 236, score -254.856026, steps 200\n",
      "iter 47599, ep 237, score -121.647198, steps 200\n",
      "iter 47799, ep 238, score -130.115954, steps 200\n",
      "iter 47999, ep 239, score -5.506703, steps 200\n",
      "iter 48199, ep 240, score -335.422943, steps 200\n",
      "iter 48399, ep 241, score -370.172429, steps 200\n",
      "iter 48599, ep 242, score -237.071299, steps 200\n",
      "iter 48799, ep 243, score -334.830867, steps 200\n",
      "iter 48999, ep 244, score -265.557115, steps 200\n",
      "iter 49199, ep 245, score -240.852207, steps 200\n",
      "iter 49399, ep 246, score -6.466158, steps 200\n",
      "iter 49599, ep 247, score -132.558734, steps 200\n",
      "iter 49799, ep 248, score -330.944252, steps 200\n",
      "iter 49999, ep 249, score -248.648816, steps 200\n",
      "iter 50199, ep 250, score -252.133982, steps 200\n",
      "iter 50399, ep 251, score -123.479560, steps 200\n",
      "iter 50599, ep 252, score -132.727016, steps 200\n",
      "iter 50799, ep 253, score -242.176115, steps 200\n",
      "iter 50999, ep 254, score -132.175714, steps 200\n",
      "iter 51199, ep 255, score -270.003987, steps 200\n",
      "iter 51399, ep 256, score -128.177940, steps 200\n",
      "iter 51599, ep 257, score -133.668196, steps 200\n",
      "iter 51799, ep 258, score -122.770314, steps 200\n",
      "iter 51999, ep 259, score -133.011755, steps 200\n",
      "iter 52199, ep 260, score -119.984557, steps 200\n",
      "iter 52399, ep 261, score -336.873420, steps 200\n",
      "iter 52599, ep 262, score -239.043861, steps 200\n",
      "iter 52799, ep 263, score -239.302411, steps 200\n",
      "iter 52999, ep 264, score -123.102939, steps 200\n",
      "iter 53199, ep 265, score -130.724306, steps 200\n",
      "iter 53399, ep 266, score -133.556476, steps 200\n",
      "iter 53599, ep 267, score -271.536447, steps 200\n",
      "iter 53799, ep 268, score -123.018146, steps 200\n",
      "iter 53999, ep 269, score -6.970198, steps 200\n",
      "iter 54199, ep 270, score -130.543401, steps 200\n",
      "iter 54399, ep 271, score -7.032991, steps 200\n",
      "iter 54599, ep 272, score -129.102556, steps 200\n",
      "iter 54799, ep 273, score -129.623063, steps 200\n",
      "iter 54999, ep 274, score -130.037734, steps 200\n",
      "iter 55199, ep 275, score -354.135605, steps 200\n",
      "iter 55399, ep 276, score -123.412699, steps 200\n",
      "iter 55599, ep 277, score -8.412939, steps 200\n",
      "iter 55799, ep 278, score -120.640051, steps 200\n",
      "iter 55999, ep 279, score -133.080594, steps 200\n",
      "iter 56199, ep 280, score -132.837005, steps 200\n",
      "iter 56399, ep 281, score -121.366445, steps 200\n",
      "iter 56599, ep 282, score -7.570586, steps 200\n",
      "iter 56799, ep 283, score -132.751188, steps 200\n",
      "iter 56999, ep 284, score -134.402747, steps 200\n",
      "iter 57199, ep 285, score -128.237481, steps 200\n",
      "iter 57399, ep 286, score -132.577115, steps 200\n",
      "iter 57599, ep 287, score -7.601648, steps 200\n",
      "iter 57799, ep 288, score -7.176242, steps 200\n",
      "iter 57999, ep 289, score -311.986878, steps 200\n",
      "iter 58199, ep 290, score -125.075807, steps 200\n",
      "iter 58399, ep 291, score -132.869319, steps 200\n",
      "iter 58599, ep 292, score -246.885029, steps 200\n",
      "iter 58799, ep 293, score -136.779909, steps 200\n",
      "iter 58999, ep 294, score -118.865635, steps 200\n",
      "iter 59199, ep 295, score -125.123747, steps 200\n",
      "iter 59399, ep 296, score -266.036222, steps 200\n",
      "iter 59599, ep 297, score -280.558942, steps 200\n",
      "iter 59799, ep 298, score -6.365290, steps 200\n",
      "iter 59999, ep 299, score -333.505314, steps 200\n",
      "iter 60199, ep 300, score -257.021949, steps 200\n",
      "iter 60399, ep 301, score -3.614302, steps 200\n",
      "iter 60599, ep 302, score -122.959251, steps 200\n",
      "iter 60799, ep 303, score -232.235837, steps 200\n",
      "iter 60999, ep 304, score -237.746261, steps 200\n",
      "iter 61199, ep 305, score -121.236568, steps 200\n",
      "iter 61399, ep 306, score -243.285471, steps 200\n",
      "iter 61599, ep 307, score -123.550587, steps 200\n",
      "iter 61799, ep 308, score -128.397281, steps 200\n",
      "iter 61999, ep 309, score -128.373443, steps 200\n",
      "iter 62199, ep 310, score -128.597447, steps 200\n",
      "iter 62399, ep 311, score -116.914463, steps 200\n",
      "iter 62599, ep 312, score -240.864486, steps 200\n",
      "iter 62799, ep 313, score -122.356025, steps 200\n",
      "iter 62999, ep 314, score -120.251762, steps 200\n",
      "iter 63199, ep 315, score -239.192689, steps 200\n",
      "iter 63399, ep 316, score -126.717909, steps 200\n",
      "iter 63599, ep 317, score -245.941814, steps 200\n",
      "iter 63799, ep 318, score -127.907692, steps 200\n",
      "iter 63999, ep 319, score -243.145524, steps 200\n",
      "iter 64199, ep 320, score -116.222546, steps 200\n",
      "iter 64399, ep 321, score -5.437299, steps 200\n",
      "iter 64599, ep 322, score -260.395145, steps 200\n",
      "iter 64799, ep 323, score -244.930093, steps 200\n",
      "iter 64999, ep 324, score -242.066035, steps 200\n",
      "iter 65199, ep 325, score -247.987432, steps 200\n",
      "iter 65399, ep 326, score -276.596887, steps 200\n",
      "iter 65599, ep 327, score -242.305310, steps 200\n",
      "iter 65799, ep 328, score -129.111124, steps 200\n",
      "iter 65999, ep 329, score -126.496342, steps 200\n",
      "iter 66199, ep 330, score -127.199991, steps 200\n",
      "iter 66399, ep 331, score -4.191070, steps 200\n",
      "iter 66599, ep 332, score -125.634870, steps 200\n",
      "iter 66799, ep 333, score -256.336007, steps 200\n",
      "iter 66999, ep 334, score -235.038112, steps 200\n",
      "iter 67199, ep 335, score -244.274242, steps 200\n",
      "iter 67399, ep 336, score -4.488644, steps 200\n",
      "iter 67599, ep 337, score -4.704433, steps 200\n",
      "iter 67799, ep 338, score -314.068747, steps 200\n",
      "iter 67999, ep 339, score -128.962556, steps 200\n",
      "iter 68199, ep 340, score -352.277938, steps 200\n",
      "iter 68399, ep 341, score -119.929162, steps 200\n",
      "iter 68595, ep 342"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-26 21:30:27,232] Starting new video recorder writing to /Users/winter/Google Drive/handson-ml/tmp/openaigym.video.0.1408.video000343.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 68599, ep 342, score -366.539098, steps 200\n",
      "iter 68799, ep 343, score -119.283715, steps 200\n",
      "iter 68999, ep 344, score -264.026636, steps 200\n",
      "iter 69199, ep 345, score -127.457260, steps 200\n",
      "iter 69399, ep 346, score -126.855899, steps 200\n",
      "iter 69599, ep 347, score -116.423614, steps 200\n",
      "iter 69799, ep 348, score -365.954037, steps 200\n",
      "iter 69999, ep 349, score -267.084830, steps 200\n",
      "iter 70199, ep 350, score -125.671618, steps 200\n",
      "iter 70399, ep 351, score -368.480243, steps 200\n",
      "iter 70599, ep 352, score -235.926462, steps 200\n",
      "iter 70799, ep 353, score -125.897110, steps 200\n",
      "iter 70999, ep 354, score -298.170883, steps 200\n",
      "iter 71199, ep 355, score -336.450492, steps 200\n",
      "iter 71399, ep 356, score -358.646415, steps 200\n",
      "iter 71599, ep 357, score -129.539452, steps 200\n",
      "iter 71799, ep 358, score -126.687282, steps 200\n",
      "iter 71999, ep 359, score -128.661384, steps 200\n",
      "iter 72199, ep 360, score -124.836461, steps 200\n",
      "iter 72399, ep 361, score -239.609822, steps 200\n",
      "iter 72599, ep 362, score -128.085954, steps 200\n",
      "iter 72799, ep 363, score -250.857986, steps 200\n",
      "iter 72999, ep 364, score -367.498097, steps 200\n",
      "iter 73199, ep 365, score -118.573546, steps 200\n",
      "iter 73399, ep 366, score -357.616653, steps 200\n",
      "iter 73599, ep 367, score -238.981204, steps 200\n",
      "iter 73799, ep 368, score -4.328976, steps 200\n",
      "iter 73999, ep 369, score -242.917910, steps 200\n",
      "iter 74199, ep 370, score -372.671354, steps 200\n",
      "iter 74399, ep 371, score -245.484786, steps 200\n",
      "iter 74599, ep 372, score -127.712747, steps 200\n",
      "iter 74799, ep 373, score -246.383811, steps 200\n",
      "iter 74999, ep 374, score -4.345438, steps 200\n",
      "iter 75199, ep 375, score -266.373024, steps 200\n",
      "iter 75399, ep 376, score -122.290439, steps 200\n",
      "iter 75599, ep 377, score -270.718117, steps 200\n",
      "iter 75799, ep 378, score -4.465336, steps 200\n",
      "iter 75999, ep 379, score -236.911200, steps 200\n",
      "iter 76199, ep 380, score -356.773776, steps 200\n",
      "iter 76399, ep 381, score -130.141630, steps 200\n",
      "iter 76599, ep 382, score -233.822707, steps 200\n",
      "iter 76799, ep 383, score -248.834029, steps 200\n",
      "iter 76999, ep 384, score -254.197619, steps 200\n",
      "iter 77199, ep 385, score -130.698491, steps 200\n",
      "iter 77399, ep 386, score -130.011718, steps 200\n",
      "iter 77599, ep 387, score -130.616305, steps 200\n",
      "iter 77799, ep 388, score -132.142333, steps 200\n",
      "iter 77999, ep 389, score -4.970126, steps 200\n",
      "iter 78199, ep 390, score -4.525809, steps 200\n",
      "iter 78399, ep 391, score -349.493168, steps 200\n",
      "iter 78599, ep 392, score -4.509693, steps 200\n",
      "iter 78799, ep 393, score -120.290129, steps 200\n",
      "iter 78999, ep 394, score -124.072395, steps 200\n",
      "iter 79199, ep 395, score -117.970291, steps 200\n",
      "iter 79399, ep 396, score -119.131752, steps 200\n",
      "iter 79599, ep 397, score -123.907668, steps 200\n",
      "iter 79799, ep 398, score -127.259068, steps 200\n",
      "iter 79999, ep 399, score -272.045071, steps 200\n",
      "iter 80199, ep 400, score -122.568052, steps 200\n",
      "iter 80399, ep 401, score -128.302822, steps 200\n",
      "iter 80599, ep 402, score -242.071540, steps 200\n",
      "iter 80799, ep 403, score -236.555885, steps 200\n",
      "iter 80999, ep 404, score -254.638892, steps 200\n",
      "iter 81199, ep 405, score -4.559032, steps 200\n",
      "iter 81399, ep 406, score -338.747843, steps 200\n",
      "iter 81599, ep 407, score -271.123363, steps 200\n",
      "iter 81799, ep 408, score -129.768551, steps 200\n",
      "iter 81999, ep 409, score -130.282053, steps 200\n",
      "iter 82199, ep 410, score -132.270137, steps 200\n",
      "iter 82399, ep 411, score -238.836504, steps 200\n",
      "iter 82599, ep 412, score -122.466685, steps 200\n",
      "iter 82799, ep 413, score -338.361574, steps 200\n",
      "iter 82999, ep 414, score -131.548065, steps 200\n",
      "iter 83199, ep 415, score -133.290980, steps 200\n",
      "iter 83399, ep 416, score -134.987242, steps 200\n",
      "iter 83599, ep 417, score -134.078996, steps 200\n",
      "iter 83799, ep 418, score -126.560450, steps 200\n",
      "iter 83999, ep 419, score -124.045671, steps 200\n",
      "iter 84199, ep 420, score -252.840873, steps 200\n",
      "iter 84399, ep 421, score -119.901363, steps 200\n",
      "iter 84599, ep 422, score -248.463898, steps 200\n",
      "iter 84799, ep 423, score -259.310671, steps 200\n",
      "iter 84999, ep 424, score -5.879516, steps 200\n",
      "iter 85199, ep 425, score -125.992997, steps 200\n",
      "iter 85399, ep 426, score -130.772884, steps 200\n",
      "iter 85599, ep 427, score -133.960069, steps 200\n",
      "iter 85799, ep 428, score -128.748451, steps 200\n",
      "iter 85999, ep 429, score -5.323233, steps 200\n",
      "iter 86199, ep 430, score -125.930848, steps 200\n",
      "iter 86399, ep 431, score -131.249564, steps 200\n",
      "iter 86599, ep 432, score -121.955848, steps 200\n",
      "iter 86799, ep 433, score -126.726698, steps 200\n",
      "iter 86999, ep 434, score -129.092343, steps 200\n",
      "iter 87199, ep 435, score -120.472004, steps 200\n",
      "iter 87399, ep 436, score -123.544131, steps 200\n",
      "iter 87599, ep 437, score -253.988645, steps 200\n",
      "iter 87799, ep 438, score -123.497215, steps 200\n",
      "iter 87999, ep 439, score -3.045889, steps 200\n",
      "iter 88199, ep 440, score -120.507718, steps 200\n",
      "iter 88399, ep 441, score -240.431019, steps 200\n",
      "iter 88599, ep 442, score -3.009580, steps 200\n",
      "iter 88799, ep 443, score -307.113333, steps 200\n",
      "iter 88999, ep 444, score -127.279165, steps 200\n",
      "iter 89199, ep 445, score -122.846385, steps 200\n",
      "iter 89399, ep 446, score -124.607087, steps 200\n",
      "iter 89599, ep 447, score -238.558577, steps 200\n",
      "iter 89799, ep 448, score -233.133597, steps 200\n",
      "iter 89999, ep 449, score -122.499911, steps 200\n",
      "iter 90199, ep 450, score -234.558908, steps 200\n",
      "iter 90399, ep 451, score -322.962568, steps 200\n",
      "iter 90599, ep 452, score -231.654030, steps 200\n",
      "iter 90799, ep 453, score -124.538077, steps 200\n",
      "iter 90999, ep 454, score -239.473319, steps 200\n",
      "iter 91199, ep 455, score -267.782583, steps 200\n",
      "iter 91399, ep 456, score -301.449482, steps 200\n",
      "iter 91599, ep 457, score -119.068361, steps 200\n",
      "iter 91799, ep 458, score -123.199646, steps 200\n",
      "iter 91999, ep 459, score -119.289888, steps 200\n",
      "iter 92199, ep 460, score -344.746766, steps 200\n",
      "iter 92399, ep 461, score -131.218601, steps 200\n",
      "iter 92599, ep 462, score -124.328458, steps 200\n",
      "iter 92799, ep 463, score -242.595299, steps 200\n",
      "iter 92999, ep 464, score -118.777685, steps 200\n",
      "iter 93199, ep 465, score -124.753331, steps 200\n",
      "iter 93399, ep 466, score -125.403707, steps 200\n",
      "iter 93599, ep 467, score -354.711999, steps 200\n",
      "iter 93799, ep 468, score -123.824846, steps 200\n",
      "iter 93999, ep 469, score -128.554761, steps 200\n",
      "iter 94199, ep 470, score -129.176413, steps 200\n",
      "iter 94399, ep 471, score -121.574554, steps 200\n",
      "iter 94599, ep 472, score -116.763944, steps 200\n",
      "iter 94799, ep 473, score -125.687042, steps 200\n",
      "iter 94999, ep 474, score -2.600989, steps 200\n",
      "iter 95199, ep 475, score -252.568422, steps 200\n",
      "iter 95399, ep 476, score -261.405147, steps 200\n",
      "iter 95599, ep 477, score -257.657228, steps 200\n",
      "iter 95799, ep 478, score -119.638925, steps 200\n",
      "iter 95999, ep 479, score -126.184898, steps 200\n",
      "iter 96199, ep 480, score -5.295040, steps 200\n",
      "iter 96399, ep 481, score -262.848053, steps 200\n",
      "iter 96599, ep 482, score -276.019287, steps 200\n",
      "iter 96799, ep 483, score -118.643215, steps 200\n",
      "iter 96999, ep 484, score -133.585187, steps 200\n",
      "iter 97199, ep 485, score -132.039005, steps 200\n",
      "iter 97399, ep 486, score -121.752587, steps 200\n",
      "iter 97599, ep 487, score -259.833304, steps 200\n",
      "iter 97799, ep 488, score -128.846781, steps 200\n",
      "iter 97999, ep 489, score -369.836613, steps 200\n",
      "iter 98199, ep 490, score -116.918012, steps 200\n",
      "iter 98399, ep 491, score -123.747513, steps 200\n",
      "iter 98599, ep 492, score -4.510867, steps 200\n",
      "iter 98799, ep 493, score -121.577638, steps 200\n",
      "iter 98999, ep 494, score -120.418638, steps 200\n",
      "iter 99199, ep 495, score -351.277637, steps 200\n",
      "iter 99399, ep 496, score -118.680903, steps 200\n",
      "iter 99599, ep 497, score -118.259936, steps 200\n",
      "iter 99799, ep 498, score -351.153567, steps 200\n",
      "iter 99999, ep 499, score -244.595728, steps 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-26 21:34:01,853] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/winter/Google Drive/handson-ml/tmp')\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "max_episode = 500\n",
    "gamma = 0.99\n",
    "tau = 0.001\n",
    "memory_size = 10000\n",
    "batch_size = 256\n",
    "memory_warmup = batch_size*3\n",
    "max_explore_eps = 100\n",
    "save_path = 'DDPG_net_Class.ckpt'\n",
    "\n",
    "tf.reset_default_graph()\n",
    "actorAsync = AsyncNets('Actor')\n",
    "actor,actor_target = actorAsync.get_subnets()\n",
    "criticAsync = AsyncNets('Critic')\n",
    "critic,critic_target = criticAsync.get_subnets()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    actorAsync.set_session(sess)\n",
    "    criticAsync.set_session(sess)\n",
    "    env = gym.make('Pendulum-v0')\n",
    "    env = wrappers.Monitor(env,'./tmp/',force=True)\n",
    "    obs = env.reset()\n",
    "    iteration = 0\n",
    "    episode = 0\n",
    "    episode_score = 0\n",
    "    episode_steps = 0\n",
    "    noise = UONoise()\n",
    "    memory = Memory(memory_size)\n",
    "    while episode < max_episode:\n",
    "        print('\\riter {}, ep {}'.format(iteration,episode),end='')\n",
    "        action = actor.predict_action(np.reshape(obs,[1,-1]))[0]\n",
    "        if episode<max_explore_eps: # exploration policy\n",
    "            p = episode/max_explore_eps\n",
    "            action = action*p + (1-p)*next(noise)\n",
    "        action *= 2 # scale action\n",
    "        next_obs, reward, done,info = env.step(action)\n",
    "        memory.append([obs,action,reward,next_obs,done])\n",
    "        if iteration >= memory_warmup:\n",
    "            memory_batch = memory.sample_batch(batch_size)\n",
    "            extract_mem = lambda k : np.array([item[k] for item in memory_batch])\n",
    "            obs_batch = extract_mem(0)\n",
    "            action_batch = extract_mem(1)\n",
    "            reward_batch = extract_mem(2)\n",
    "            next_obs_batch = extract_mem(3)\n",
    "            done_batch = extract_mem(4)\n",
    "            action_next = actor_target.predict_action(next_obs_batch)\n",
    "            Q_next = critic_target.predict_Q(next_obs_batch,action_next)[:,0]\n",
    "            Qexpected_batch = reward_batch + gamma*(1-done_batch)*Q_next # target Q value\n",
    "            Qexpected_batch = np.reshape(Qexpected_batch,[-1,1])\n",
    "            # train critic\n",
    "            critic.train(obs_batch,action_batch,Qexpected_batch)\n",
    "            # train actor\n",
    "            action_grads = critic.compute_action_grads(obs_batch,action_batch)\n",
    "            actor.train(obs_batch,action_grads)\n",
    "            # async update\n",
    "            actorAsync.async_update(tau)\n",
    "            criticAsync.async_update(tau)\n",
    "        episode_score += reward\n",
    "        episode_steps += 1\n",
    "        iteration += 1\n",
    "        if done:\n",
    "            print(', score {:8f}, steps {}'.format(episode_score,episode_steps))\n",
    "#             if episode%5 == 0:\n",
    "                \n",
    "#                 Q_check = \n",
    "            obs = env.reset()\n",
    "            episode += 1\n",
    "            episode_score = 0\n",
    "            episode_steps = 0\n",
    "            noise = UONoise()\n",
    "            if episode%100==0:\n",
    "                saver.save(sess,save_path)\n",
    "        else:\n",
    "            obs = next_obs\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-26 21:34:01,863] [Pendulum-v0] Uploading 500 episodes of training data\n",
      "[2017-08-26 21:34:03,713] [Pendulum-v0] Uploading videos of 8 training episodes (628501 bytes)\n",
      "[2017-08-26 21:34:05,040] [Pendulum-v0] Creating evaluation object from ./tmp/ with learning curve and training video\n",
      "[2017-08-26 21:34:05,260] \n",
      "****************************************************\n",
      "You successfully uploaded your evaluation on Pendulum-v0 to\n",
      "OpenAI Gym! You can find it at:\n",
      "\n",
      "    https://gym.openai.com/evaluations/eval_ZVyGQYhVTb67h0Vu6UtOYQ\n",
      "\n",
      "****************************************************\n"
     ]
    }
   ],
   "source": [
    "gym.upload('./tmp/', api_key='sk_BlwjttPKR6ZsXVrObENYA')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
